{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0898c8",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59ce8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Download the ZIP\n",
    "url = \"https://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "r = requests.get(url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "# 2. Extract (in memory or to disk)\n",
    "data_folder = \"ml-100k\"\n",
    "if not os.path.exists(data_folder):\n",
    "    z.extractall(data_folder)\n",
    "\n",
    "# 3. Load ratings file\n",
    "ratings_path = os.path.join(data_folder, \"u.data\")\n",
    "ratings = pd.read_csv(ratings_path, sep=\"\\t\",\n",
    "                      names=[\"user_id\",\"item_id\",\"rating\",\"timestamp\"],\n",
    "                      engine=\"python\")\n",
    "\n",
    "# 4. Load movie metadata (optional)\n",
    "movies_path = os.path.join(data_folder, \"u.item\")\n",
    "# u.item uses '|' as separator — adapt encoding if needed\n",
    "movies = pd.read_csv(movies_path, sep=\"|\", \n",
    "                     names=[\"item_id\",\"title\",\"release_date\",\n",
    "                            \"video_release_date\",\"IMDb_URL\"] + [f\"genre_{i}\" for i in range(19)],\n",
    "                     encoding=\"latin-1\", engine=\"python\")\n",
    "\n",
    "print(\"Ratings sample:\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c173229e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movies sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>IMDb_URL</th>\n",
       "      <th>genre_0</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>genre_3</th>\n",
       "      <th>genre_4</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_9</th>\n",
       "      <th>genre_10</th>\n",
       "      <th>genre_11</th>\n",
       "      <th>genre_12</th>\n",
       "      <th>genre_13</th>\n",
       "      <th>genre_14</th>\n",
       "      <th>genre_15</th>\n",
       "      <th>genre_16</th>\n",
       "      <th>genre_17</th>\n",
       "      <th>genre_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id              title release_date  video_release_date  \\\n",
       "0        1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "1        2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "2        3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "3        4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "4        5     Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                            IMDb_URL  genre_0  genre_1  \\\n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0        0   \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0        1   \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0        0   \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0        1   \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0        0   \n",
       "\n",
       "   genre_2  genre_3  genre_4  ...  genre_9  genre_10  genre_11  genre_12  \\\n",
       "0        0        1        1  ...        0         0         0         0   \n",
       "1        1        0        0  ...        0         0         0         0   \n",
       "2        0        0        0  ...        0         0         0         0   \n",
       "3        0        0        0  ...        0         0         0         0   \n",
       "4        0        0        0  ...        0         0         0         0   \n",
       "\n",
       "   genre_13  genre_14  genre_15  genre_16  genre_17  genre_18  \n",
       "0         0         0         0         0         0         0  \n",
       "1         0         0         0         1         0         0  \n",
       "2         0         0         0         1         0         0  \n",
       "3         0         0         0         0         0         0  \n",
       "4         0         0         0         1         0         0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nMovies sample:\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c324449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Info:\n",
      "Number of ratings: 100000\n",
      "Number of movies: 1682\n",
      "Number of unique users: 943\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Info:\")\n",
    "print(f\"Number of ratings: {len(ratings)}\")\n",
    "print(f\"Number of movies: {len(movies)}\")\n",
    "print(f\"Number of unique users: {ratings['user_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4a5c55",
   "metadata": {},
   "source": [
    "## Matrix Factorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91ccf48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/25 — MSE: 5.8003\n",
      "Epoch 02/25 — MSE: 1.4519\n",
      "Epoch 03/25 — MSE: 1.0439\n",
      "Epoch 04/25 — MSE: 0.9269\n",
      "Epoch 05/25 — MSE: 0.8664\n",
      "Epoch 06/25 — MSE: 0.8228\n",
      "Epoch 07/25 — MSE: 0.7862\n",
      "Epoch 08/25 — MSE: 0.7513\n",
      "Epoch 09/25 — MSE: 0.7192\n",
      "Epoch 10/25 — MSE: 0.6879\n",
      "Epoch 11/25 — MSE: 0.6598\n",
      "Epoch 12/25 — MSE: 0.6321\n",
      "Epoch 13/25 — MSE: 0.6077\n",
      "Epoch 14/25 — MSE: 0.5831\n",
      "Epoch 15/25 — MSE: 0.5610\n",
      "Epoch 16/25 — MSE: 0.5420\n",
      "Epoch 17/25 — MSE: 0.5236\n",
      "Epoch 18/25 — MSE: 0.5070\n",
      "Epoch 19/25 — MSE: 0.4928\n",
      "Epoch 20/25 — MSE: 0.4799\n",
      "Epoch 21/25 — MSE: 0.4680\n",
      "Epoch 22/25 — MSE: 0.4573\n",
      "Epoch 23/25 — MSE: 0.4458\n",
      "Epoch 24/25 — MSE: 0.4373\n",
      "Epoch 25/25 — MSE: 0.4296\n",
      "\n",
      "Test MSE: 0.9438673871144647\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 1. Split the data\n",
    "train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Build MF training data\n",
    "num_users = ratings['user_id'].nunique()\n",
    "num_items = ratings['item_id'].nunique()\n",
    "\n",
    "# Zero-index user and item IDs for training set\n",
    "train_user_ids = train_data['user_id'].values - 1\n",
    "train_item_ids = train_data['item_id'].values - 1\n",
    "train_ratings_vals = train_data['rating'].values\n",
    "\n",
    "train_ratings = list(zip(train_user_ids, train_item_ids, train_ratings_vals))\n",
    "n_train = len(train_ratings)\n",
    "\n",
    "# 3. MF SGD Implementation\n",
    "\n",
    "def train_mf_sgd(num_users, num_items, data, k=20, epochs=25, lr=0.01, reg=0.02, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    P = rng.normal(scale=0.1, size=(num_users, k))\n",
    "    Q = rng.normal(scale=0.1, size=(num_items, k))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        rng.shuffle(data)\n",
    "\n",
    "        for u, i, r in data:\n",
    "            pred = np.dot(P[u], Q[i])\n",
    "            err = r - pred\n",
    "\n",
    "            # Gradient update\n",
    "            P[u] += lr * (err * Q[i] - reg * P[u])\n",
    "            Q[i] += lr * (err * P[u] - reg * Q[i])\n",
    "\n",
    "        # Compute MSE on training set only\n",
    "        se = 0\n",
    "        for u, i, r in data:\n",
    "            pred = np.dot(P[u], Q[i])\n",
    "            se += (r - pred) ** 2\n",
    "        mse = se / len(data)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d}/{epochs} — MSE: {mse:.4f}\")\n",
    "\n",
    "    return P, Q\n",
    "\n",
    "\n",
    "P, Q = train_mf_sgd(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    data=train_ratings,\n",
    "    k=20,\n",
    "    epochs=25,\n",
    "    lr=0.01,\n",
    "    reg=0.02\n",
    ")\n",
    "\n",
    "# 4. Evaluate on test set\n",
    "\n",
    "def predict(P, Q, u, i):\n",
    "    return np.dot(P[u], Q[i])\n",
    "\n",
    "se = 0\n",
    "for row in test_data.itertuples():\n",
    "    u = row.user_id - 1\n",
    "    i = row.item_id - 1\n",
    "    r = row.rating\n",
    "    pred = predict(P, Q, u, i)\n",
    "    se += (r - pred)**2\n",
    "\n",
    "test_mse = se / len(test_data)\n",
    "print(\"\\nTest MSE:\", test_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c454d8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 8 on item 11: 3.84\n",
      "Item title: Seven (Se7en) (1995)\n"
     ]
    }
   ],
   "source": [
    "# example prediction\n",
    "user_id = 8  # Example user ID\n",
    "item_id = 11  # Example item ID\n",
    "predicted_rating = predict(P, Q, user_id - 1, item_id - 1)\n",
    "print(f\"Predicted rating for user {user_id} on item {item_id}: {predicted_rating:.2f}\")\n",
    "print(\"Item title:\", movies[movies['item_id'] == item_id]['title'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7883dfab",
   "metadata": {},
   "source": [
    "## Neural Collaborative Filtering (NCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cad429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 — Train Loss: 0.0645\n",
      "Epoch 2/20 — Train Loss: 0.0547\n",
      "Epoch 3/20 — Train Loss: 0.0532\n",
      "Epoch 4/20 — Train Loss: 0.0524\n",
      "Epoch 5/20 — Train Loss: 0.0517\n",
      "Epoch 6/20 — Train Loss: 0.0511\n",
      "Epoch 7/20 — Train Loss: 0.0504\n",
      "Epoch 8/20 — Train Loss: 0.0495\n",
      "Epoch 9/20 — Train Loss: 0.0487\n",
      "Epoch 10/20 — Train Loss: 0.0479\n",
      "Epoch 11/20 — Train Loss: 0.0471\n",
      "Epoch 12/20 — Train Loss: 0.0464\n",
      "Epoch 13/20 — Train Loss: 0.0457\n",
      "Epoch 14/20 — Train Loss: 0.0449\n",
      "Epoch 15/20 — Train Loss: 0.0442\n",
      "Epoch 16/20 — Train Loss: 0.0434\n",
      "Epoch 17/20 — Train Loss: 0.0427\n",
      "Epoch 18/20 — Train Loss: 0.0419\n",
      "Epoch 19/20 — Train Loss: 0.0412\n",
      "Epoch 20/20 — Train Loss: 0.0405\n",
      "Test MSE: 0.8904026573217367\n",
      "Test RMSE: 0.9436114970271063\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 1. DATASET CLASS\n",
    "\n",
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.tensor(df['user_id'].values - 1, dtype=torch.long)\n",
    "        self.items = torch.tensor(df['item_id'].values - 1, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
    "\n",
    "# 2. DATA LOADERS\n",
    "\n",
    "train_loader = DataLoader(RatingDataset(train_data), batch_size=256, shuffle=True)\n",
    "test_loader  = DataLoader(RatingDataset(test_data),  batch_size=256, shuffle=False)\n",
    "\n",
    "# 3. NCF MODEL\n",
    "\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_dim=64):  # increased emb size\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
    "\n",
    "        # Optional user/item bias terms help capture global tendencies\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        # initialize embeddings/biases\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.05)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.05)\n",
    "        nn.init.zeros_(self.user_bias.weight)\n",
    "        nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        u = self.user_emb(users)\n",
    "        i = self.item_emb(items)\n",
    "        x = torch.cat([u, i], dim=1)\n",
    "        base = self.mlp(x)\n",
    "        # add user/item bias\n",
    "        return base + self.user_bias(users) + self.item_bias(items)\n",
    "\n",
    "# 4. TRAINING SETUP\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = NCF(num_users, num_items, emb_dim=64).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Add weight decay for embedding regularization and lower LR with scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0008, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "# 5. TRAINING LOOP\n",
    "\n",
    "epochs = 20  # train longer\n",
    "\n",
    "# Scale ratings to 0-1 range to stabilize training\n",
    "#  ML-100k ratings are 1-5; normalize before training and denormalize for reporting\n",
    "def scale_ratings(r): return (r - 1.0) / 4.0\n",
    "def unscale_ratings(r): return r * 4.0 + 1.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for users, items, ratings in train_loader:\n",
    "        users = users.to(device)\n",
    "        items = items.to(device)\n",
    "        ratings = scale_ratings(ratings).to(device).unsqueeze(1)\n",
    "\n",
    "        preds = torch.sigmoid(model(users, items))  # constrain to 0-1\n",
    "        loss = criterion(preds, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} — Train Loss: {avg_train_loss:.4f}\")\n",
    "    scheduler.step(avg_train_loss)\n",
    "\n",
    "# 6. EVALUATION\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "rmse_sum = 0\n",
    "n_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for users, items, ratings in test_loader:\n",
    "        users = users.to(device)\n",
    "        items = items.to(device)\n",
    "        ratings = ratings.to(device).unsqueeze(1)\n",
    "\n",
    "        preds01 = torch.sigmoid(model(users, items))\n",
    "        preds = unscale_ratings(preds01)  # back to 1-5\n",
    "        loss = criterion(preds, ratings)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # RMSE for more interpretable metric\n",
    "        rmse_sum += torch.mean((preds - ratings) ** 2).item()\n",
    "        n_batches += 1\n",
    "\n",
    "print(\"Test MSE:\", test_loss / n_batches)\n",
    "print(\"Test RMSE:\", (rmse_sum / n_batches) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9297879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 8 on item 11: 4.07\n",
      "Item title: Seven (Se7en) (1995)\n"
     ]
    }
   ],
   "source": [
    "# make example prediction\n",
    "user_id = 8  # Example user ID\n",
    "item_id = 11  # Example item ID\n",
    "user_tensor = torch.tensor([user_id - 1], dtype=torch.long).to(device)\n",
    "item_tensor = torch.tensor([item_id - 1], dtype=torch.long).to(device)\n",
    "pred01 = torch.sigmoid(model(user_tensor, item_tensor))\n",
    "pred_rating = unscale_ratings(pred01).item()\n",
    "print(f\"Predicted rating for user {user_id} on item {item_id}: {pred_rating:.2f}\")\n",
    "print(\"Item title:\", movies[movies['item_id'] == item_id]['title'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968c184",
   "metadata": {},
   "source": [
    "## Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20b96ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Build a lightweight content string: title + year + active genre names\n",
    "genre_names = [\n",
    "    'unknown','Action','Adventure','Animation','Children','Comedy','Crime',\n",
    "    'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery',\n",
    "    'Romance','Sci-Fi','Thriller','War','Western'\n",
    "]\n",
    "genre_cols = [f'genre_{i}' for i in range(19)]\n",
    "\n",
    "def _row_to_content(row):\n",
    "    title = str(row['title']) if row['title'] is not None else ''\n",
    "    rd = row['release_date']\n",
    "    year = f\"year_{str(rd)[-4:]}\" if isinstance(rd, str) and len(rd) >= 4 else ''\n",
    "    genres = [genre_names[i] for i in range(19) if row[genre_cols[i]] == 1]\n",
    "    return \" \".join([title, year] + genres)\n",
    "\n",
    "if 'content' not in movies.columns:\n",
    "    movies['content'] = movies.apply(_row_to_content, axis=1)\n",
    "\n",
    "# TF-IDF and cosine similarity matrix\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies['content'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Helper to fetch top-N similar items by item_id\n",
    "def get_similar_items(item_id, top_n=10):\n",
    "    idx_arr = movies.index[movies['item_id'] == item_id].to_numpy()\n",
    "    if len(idx_arr) == 0:\n",
    "        raise ValueError(f\"item_id {item_id} not found\")\n",
    "    idx = int(idx_arr[0])\n",
    "    sims = cosine_sim[idx]\n",
    "    top_idx = sims.argsort()[::-1]  # descending\n",
    "    top_idx = [i for i in top_idx if i != idx][:top_n]\n",
    "    result = movies.loc[top_idx, ['item_id', 'title']].copy()\n",
    "    result['similarity'] = [float(sims[i]) for i in top_idx]\n",
    "    return result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c699f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie name: Toy Story (1995)\n",
      "   item_id                              title  similarity\n",
      "0     1066                       Balto (1995)    0.391444\n",
      "1     1072  Pyromaniac's Love Story, A (1995)    0.390892\n",
      "2     1219              Goofy Movie, A (1995)    0.353428\n",
      "3      542                  Pocahontas (1995)    0.350211\n",
      "4     1470            Gumby: The Movie (1995)    0.337008\n",
      "5     1053                Now and Then (1995)    0.299264\n",
      "6      548  NeverEnding Story III, The (1994)    0.296255\n",
      "7      308     FairyTale: A True Story (1997)    0.289664\n",
      "8        8                        Babe (1995)    0.280017\n",
      "9     1344       Story of Xinghua, The (1993)    0.276277\n"
     ]
    }
   ],
   "source": [
    "# Example: show similar movies to the existing item_id variable\n",
    "item_id = 1  # Example item ID\n",
    "print(\"Movie name:\", movies[movies['item_id'] == item_id]['title'].values[0])\n",
    "print(get_similar_items(item_id, top_n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0a9ca",
   "metadata": {},
   "source": [
    "## Build the Hybrid Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d9b2d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e523e1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid score for user 8 and item 11: 3.06\n",
      "Item title: Seven (Se7en) (1995)\n"
     ]
    }
   ],
   "source": [
    "def hybrid_score(user_id, item_id, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Compute a hybrid score for a given user and item.\n",
    "    alpha: weight for collaborative (MF) score, (1-alpha) for content-based score.\n",
    "    \"\"\"\n",
    "    # Matrix Factorization prediction (collaborative)\n",
    "    mf_pred = np.dot(P[user_id - 1], Q[item_id - 1])\n",
    "\n",
    "    # Content-based similarity: average similarity to user's rated items\n",
    "    user_rated_items = train_data[train_data['user_id'] == user_id]['item_id'].values\n",
    "    if len(user_rated_items) == 0:\n",
    "        content_score = 0\n",
    "    else:\n",
    "        idx_target = movies.index[movies['item_id'] == item_id][0]\n",
    "        idx_rated = [movies.index[movies['item_id'] == iid][0] for iid in user_rated_items if iid in movies['item_id'].values]\n",
    "        sim_scores = cosine_sim[idx_target, idx_rated] if idx_rated else np.array([0])\n",
    "        content_score = np.mean(sim_scores)\n",
    "\n",
    "    # Combine scores (normalize content_score to 1-5 scale)\n",
    "    content_score_scaled = content_score * 4 + 1\n",
    "    hybrid = alpha * mf_pred + (1 - alpha) * content_score_scaled\n",
    "    return hybrid\n",
    "\n",
    "# Example usage:\n",
    "user_id = 8\n",
    "item_id = 11\n",
    "score = hybrid_score(user_id, item_id, alpha=0.7)\n",
    "print(f\"Hybrid score for user {user_id} and item {item_id}: {score:.2f}\")\n",
    "print(\"Item title:\", movies[movies['item_id'] == item_id]['title'].values[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "substack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
