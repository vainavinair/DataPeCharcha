{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05451184",
   "metadata": {},
   "source": [
    "## 1. Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015bd39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# --- Step 1: Synthetic Data ---\n",
    "x = torch.linspace(-5, 5, 100).unsqueeze(1)\n",
    "y = 3 * x + 0.8 * torch.randn(x.size())\n",
    "\n",
    "# --- Step 2: Define two different models ---\n",
    "model_A = nn.Sequential(nn.Linear(1, 1))                     \n",
    "model_B = nn.Sequential(nn.Linear(1, 10), nn.ReLU(), nn.Linear(10, 1))  \n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_A = optim.SGD(model_A.parameters(), lr=0.01)\n",
    "optimizer_B = optim.Adam(model_B.parameters(), lr=0.001)\n",
    "\n",
    "writer_A = SummaryWriter(log_dir=\"runs/model_A\")\n",
    "writer_B = SummaryWriter(log_dir=\"runs/model_B\")\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "# --- Step 3: Training loop ---\n",
    "for epoch in range(epochs):\n",
    "    # ===== Model A =====\n",
    "    optimizer_A.zero_grad()\n",
    "    outputs_A = model_A(x)\n",
    "    loss_A = criterion(outputs_A, y)\n",
    "    loss_A.backward()\n",
    "    optimizer_A.step()\n",
    "\n",
    "    # Log scalar metrics\n",
    "    writer_A.add_scalar(\"Loss/train\", loss_A.item(), epoch)\n",
    "    writer_A.add_scalar(\"LR\", optimizer_A.param_groups[0]['lr'], epoch)\n",
    "\n",
    "    # Log histograms for weights, biases, and gradients\n",
    "    for name, param in model_A.named_parameters():\n",
    "        writer_A.add_histogram(f\"{name}/weights\", param, epoch)\n",
    "        if param.grad is not None:\n",
    "            writer_A.add_histogram(f\"{name}/grads\", param.grad, epoch)\n",
    "\n",
    "    # ===== Model B =====\n",
    "    optimizer_B.zero_grad()\n",
    "    outputs_B = model_B(x)\n",
    "    loss_B = criterion(outputs_B, y)\n",
    "    loss_B.backward()\n",
    "    optimizer_B.step()\n",
    "\n",
    "    writer_B.add_scalar(\"Loss/train\", loss_B.item(), epoch)\n",
    "    writer_B.add_scalar(\"LR\", optimizer_B.param_groups[0]['lr'], epoch)\n",
    "\n",
    "    for name, param in model_B.named_parameters():\n",
    "        writer_B.add_histogram(f\"{name}/weights\", param, epoch)\n",
    "        if param.grad is not None:\n",
    "            writer_B.add_histogram(f\"{name}/grads\", param.grad, epoch)\n",
    "\n",
    "    # --- Combined loss (for easy comparison in one chart) ---\n",
    "    writer_A.add_scalars(\"Comparison/Loss\", {\"Model_A\": loss_A.item(), \"Model_B\": loss_B.item()}, epoch)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:03d}: Loss A = {loss_A.item():.4f}, Loss B = {loss_B.item():.4f}\")\n",
    "\n",
    "# --- Step 4: Visualize model predictions ---\n",
    "with torch.no_grad():\n",
    "    pred_A = model_A(x)\n",
    "    pred_B = model_B(x)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(x.numpy(), y.numpy(), label=\"True Data\", color=\"gray\")\n",
    "plt.plot(x.numpy(), pred_A.numpy(), label=\"Model A (Linear)\", color=\"blue\")\n",
    "plt.plot(x.numpy(), pred_B.numpy(), label=\"Model B (Deep)\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.title(\"Model Predictions\")\n",
    "plt.savefig(\"predictions.png\")\n",
    "\n",
    "# Log the comparison plot as image\n",
    "image = np.moveaxis(plt.imread(\"predictions.png\"), -1, 0)\n",
    "writer_A.add_image(\"Predictions\", image)\n",
    "writer_B.add_image(\"Predictions\", image)\n",
    "\n",
    "# --- Step 5: Flush and close writers ---\n",
    "writer_A.flush()\n",
    "writer_B.flush()\n",
    "writer_A.close()\n",
    "writer_B.close()\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"Training complete. Use TensorBoard to visualize the logs.\")\n",
    "print(\"Run: tensorboard --logdir=runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e75428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>d:\\The-Office\\Substack\\experiment-tracking\\wandb\\offline-run-20251012_135828-fd8689fk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Loss A: 41.1978 | Loss B: 78.0126\n",
      "Epoch 010 | Loss A: 1.7731 | Loss B: 62.0151\n",
      "Epoch 020 | Loss A: 0.8247 | Loss B: 47.5393\n",
      "Epoch 030 | Loss A: 0.8018 | Loss B: 32.7020\n",
      "Epoch 040 | Loss A: 0.8012 | Loss B: 18.1579\n",
      "Epoch 050 | Loss A: 0.8012 | Loss B: 7.2090\n",
      "Epoch 060 | Loss A: 0.8011 | Loss B: 2.3166\n",
      "Epoch 070 | Loss A: 0.8011 | Loss B: 1.2696\n",
      "Epoch 080 | Loss A: 0.8011 | Loss B: 1.1545\n",
      "Epoch 090 | Loss A: 0.8011 | Loss B: 1.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss/Model_A</td><td>█▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss/Model_B</td><td>█▇▇▇▇▆▅▅▅▄▄▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss/Model_A</td><td>0.80111</td></tr><tr><td>Loss/Model_B</td><td>1.01966</td></tr><tr><td>epoch</td><td>99</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br><code>wandb sync d:\\The-Office\\Substack\\experiment-tracking\\wandb\\offline-run-20251012_135828-fd8689fk<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\offline-run-20251012_135828-fd8689fk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training complete! You can view your run on W&B online dashboard.\n"
     ]
    }
   ],
   "source": [
    "# --- Install wandb if not installed ---\n",
    "# pip install wandb torch matplotlib\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Step 1: Synthetic Data ---\n",
    "x = torch.linspace(-5, 5, 100).unsqueeze(1)\n",
    "y = 3 * x + 0.8 * torch.randn(x.size())\n",
    "\n",
    "# --- Step 2: Define two models ---\n",
    "model_A = nn.Sequential(nn.Linear(1, 1))                     # simple linear\n",
    "model_B = nn.Sequential(nn.Linear(1, 10), nn.ReLU(), nn.Linear(10, 1))  # slightly deeper\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_A = optim.SGD(model_A.parameters(), lr=0.01)\n",
    "optimizer_B = optim.Adam(model_B.parameters(), lr=0.01)\n",
    "\n",
    "# --- Step 3: Initialize W&B project ---\n",
    "wandb.init(project=\"two-models\", name=\"Combined_Run\")\n",
    "\n",
    "# Optional: Watch models to log weights and gradients\n",
    "wandb.watch(model_A, log=\"all\", log_freq=10)\n",
    "wandb.watch(model_B, log=\"all\", log_freq=10)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "# --- Step 4: Training Loop ---\n",
    "for epoch in range(epochs):\n",
    "    # ---- Train Model A ----\n",
    "    optimizer_A.zero_grad()\n",
    "    out_A = model_A(x)\n",
    "    loss_A = criterion(out_A, y)\n",
    "    loss_A.backward()\n",
    "    optimizer_A.step()\n",
    "\n",
    "    # ---- Train Model B ----\n",
    "    optimizer_B.zero_grad()\n",
    "    out_B = model_B(x)\n",
    "    loss_B = criterion(out_B, y)\n",
    "    loss_B.backward()\n",
    "    optimizer_B.step()\n",
    "\n",
    "    # ---- Log metrics for both models ----\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"Loss/Model_A\": loss_A.item(),\n",
    "        \"Loss/Model_B\": loss_B.item()\n",
    "    })\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:03d} | Loss A: {loss_A.item():.4f} | Loss B: {loss_B.item():.4f}\")\n",
    "\n",
    "# --- Step 5: Log prediction plots ---\n",
    "with torch.no_grad():\n",
    "    pred_A = model_A(x).detach().numpy()\n",
    "    pred_B = model_B(x).detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(x.numpy(), y.numpy(), label=\"True Data\", color=\"gray\")\n",
    "plt.plot(x.numpy(), pred_A, label=\"Model A Prediction\", color=\"blue\")\n",
    "plt.plot(x.numpy(), pred_B, label=\"Model B Prediction\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.title(\"Model Predictions\")\n",
    "plt.savefig(\"predictions.png\")\n",
    "plt.close()\n",
    "\n",
    "# Log the plot to W&B\n",
    "wandb.log({\"Predictions\": wandb.Image(\"predictions.png\")})\n",
    "\n",
    "# --- Step 6: Finish W&B run ---\n",
    "wandb.finish()\n",
    "\n",
    "print(\"Training complete! You can view your run on W&B online dashboard.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e229ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_A | Epoch 000 | Loss: 101.1440\n",
      "Model_A | Epoch 010 | Loss: 3.3405\n",
      "Model_A | Epoch 020 | Loss: 0.8533\n",
      "Model_A | Epoch 030 | Loss: 0.7037\n",
      "Model_A | Epoch 040 | Loss: 0.6402\n",
      "Model_A | Epoch 050 | Loss: 0.5986\n",
      "Model_A | Epoch 060 | Loss: 0.5709\n",
      "Model_A | Epoch 070 | Loss: 0.5524\n",
      "Model_A | Epoch 080 | Loss: 0.5400\n",
      "Model_A | Epoch 090 | Loss: 0.5318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/12 14:02:18 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Downloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 1598.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_B | Epoch 000 | Loss: 104.0675\n",
      "Model_B | Epoch 010 | Loss: 84.1900\n",
      "Model_B | Epoch 020 | Loss: 70.6771\n",
      "Model_B | Epoch 030 | Loss: 59.6342\n",
      "Model_B | Epoch 040 | Loss: 48.2134\n",
      "Model_B | Epoch 050 | Loss: 35.3818\n",
      "Model_B | Epoch 060 | Loss: 22.2125\n",
      "Model_B | Epoch 070 | Loss: 11.0660\n",
      "Model_B | Epoch 080 | Loss: 4.1188\n",
      "Model_B | Epoch 090 | Loss: 1.5975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/12 14:02:30 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Downloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 419.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete! Start MLflow UI:\n",
      "python -m mlflow ui --backend-store-uri file:///D:\\The-Office\\Substack\\experiment-tracking\n",
      "Open http://127.0.0.1:5000 in your browser.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# --- Windows-friendly paths ---\n",
    "MLFLOW_RUNS_PATH = \"D:\\\\The-Office\\\\Substack\\\\experiment-tracking\"  # change if needed\n",
    "os.makedirs(MLFLOW_RUNS_PATH, exist_ok=True)\n",
    "mlflow.set_tracking_uri(f\"file:///{MLFLOW_RUNS_PATH}\")\n",
    "mlflow.set_experiment(\"Two_Model_Comparison\")\n",
    "\n",
    "# --- Synthetic Data ---\n",
    "x = torch.linspace(-5, 5, 100).unsqueeze(1)\n",
    "y = 3 * x + 0.8 * torch.randn(x.size())\n",
    "\n",
    "# --- Models ---\n",
    "model_A = nn.Sequential(nn.Linear(1, 1))\n",
    "model_B = nn.Sequential(nn.Linear(1, 10), nn.ReLU(), nn.Linear(10, 1))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_A = optim.SGD(model_A.parameters(), lr=0.01)\n",
    "optimizer_B = optim.Adam(model_B.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "# --- Train & log model function ---\n",
    "def train_model(model, optimizer, model_name):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"optimizer\", optimizer.__class__.__name__)\n",
    "        mlflow.log_param(\"learning_rate\", optimizer.param_groups[0]['lr'])\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log loss per epoch\n",
    "            mlflow.log_metric(\"train_loss\", loss.item(), step=epoch)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"{model_name} | Epoch {epoch:03d} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # --- Log model with input example (convert tensor to numpy) ---\n",
    "        mlflow.pytorch.log_model(model, name=\"model\", input_example=x[:5].numpy())\n",
    "\n",
    "        # --- Log prediction plot ---\n",
    "        with torch.no_grad():\n",
    "            preds = model(x).detach().numpy()\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.scatter(x.numpy(), y.numpy(), label=\"True Data\", color=\"gray\")\n",
    "        plt.plot(x.numpy(), preds, label=f\"{model_name} Prediction\", color=\"orange\")\n",
    "        plt.legend()\n",
    "        plt.title(f\"{model_name} Predictions\")\n",
    "        plot_path = f\"{model_name}_predictions.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(plot_path)\n",
    "\n",
    "# --- Train both models ---\n",
    "train_model(model_A, optimizer_A, \"Model_A\")\n",
    "train_model(model_B, optimizer_B, \"Model_B\")\n",
    "\n",
    "print(\"\\nTraining complete! Start MLflow UI:\")\n",
    "print(f\"python -m mlflow ui --backend-store-uri file:///{MLFLOW_RUNS_PATH}\")\n",
    "print(\"Open http://127.0.0.1:5000 in your browser.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696411a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "substack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
